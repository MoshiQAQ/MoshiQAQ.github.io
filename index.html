<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Zhaoyang Yu's Homepage</title>
    <style>
        body { 
            font-family: Arial, sans-serif; 
            margin: 0; 
            padding: 0; 
            padding-top: 50px;
            display: flex; 
            flex-direction: column; 
            align-items: center; 
            justify-content: center; 
            min-height: 100vh; 
            text-align: center; 
            margin-left: 15%;
            margin-right: 15%;
        }
        header { 
            display: flex; 
            align-items: center; 
            justify-content: flex-start; 
            width: 80%; 
            margin-bottom: 20px; 
        }
        header img {
            margin-left: 16%;
            margin-right: 16%; /* Adds space between the image and the text */
        }
        header > div {
            text-align: left; /* Aligns the text to the left */
        }
        section { 
            margin-bottom: 20px; 
            width: 80%; 
        }
        h2 { 
            text-align: left; 
            width: 100%;
        }
        h2::after {
            content: "";
            display: block;
            height: 2px;
            width: 100%;
            background: linear-gradient(to right, gray, transparent, transparent);
            margin-top: 5px;
        }
        .publication, .experience { 
            margin-left: 20px; 
            text-align: left; 
        }
        .publication:before, .experience:before { 
            content: "- "; 
        }
        .logo {
            height: 50px; /* Adjust based on your preference */
            margin-left: 10px; /* Adds space between the text and the logo */
            vertical-align: middle; /* Aligns the logo with the middle of the text */
        }
        .list-item{
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 10px;
        }
        .text-content {
            text-align: left;
            font-size: 1.1em;
        }
        .time {
            font-style: italic;
            font-size: 0.6em;
            color: gray;
        }
        .big-name{
            font-size: 1em;
            margin-bottom: 10px;
        }
        .small-content{
            font-size: 0.9em;
        }
        a:link, a:visited, a:hover, a:active {
            color: blue; /* Keeps the link color consistent with the surrounding text or specified color */
            text-decoration: none; /* Removes underline from links */
        }
        @media (max-width: 600px) {
            /* 手机端不显示头像 */
            header img {
                display: none;
            }
            body, header, section {
                margin-left: 10px; /* 在手机屏幕上减少左边距 */
                margin-right: 10px; /* 在手机屏幕上减少右边距 */
            }
            header{
                /* 左对齐 */
                text-align: left;
                width: auto; /* 让header的宽度自适应 */
            }
            section {
                width: calc(100% - 20px); /* 让section的宽度自适应 */
            }
        }
    </style>
</head>
<body>
    <header>
        <img src="./assets/img/zhaoyang_512.png" alt="Zhaoyang Yu" style="height: 150px;"> <!-- Adjust the image path and style as needed -->
        <div>
            <h1>Zhaoyang Yu<br>于兆洋</h1>
            <p>Email: yuzhaoyang0713 [AT] ruc.edu.cn</p> <!-- Update the email address -->
            <p><a href="https://github.com/MoshiQAQ">GitHub</a> • <a href="https://www.zhihu.com/people/arecritezhu">Zhihu</a> • <a href="https://twitter.com/ZhaoyangYu22356">Twitter</a></p>
        </div>
    </header>

    <section id="bio">
        <p class="text-content">I received my undergraduate degree from Gaoling School of AI, Renmin University of China in June 2024. I'm actively seeking a <strong>Research Intern / PhD</strong> position at present. My research interest include <strong>LLMs Agent, Embodied AI Agent</strong>.</p>
        <p class="text-content">From 2021 to 2022, I had the privilege of studying computer vision, multi-modal machine learning, and robotics under the mentorship of Prof.
        <a href="https://dtaoo.github.io/">Di Hu</a>. In 2024, I engaged in research on the memory mechanisms of LLMs Agent, advised by Prof. <a href="https://xu-chen.com/">Xu Chen</a>.</p>
    </section>

    <section id="publications">
        <h2>Publications</h2>
        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">MobileExperts: A Dynamic Tool-Enabled Agent Team in Mobile Devices</strong><br>
                <span class="small-content">Jiayi Zhang, Chuang Zhao, Yihan Zhao, <strong>Zhaoyang Yu</strong>, Ming He, Jianping Fan<sup>&ast;</sup>.</span><br>
                <span class="small-content"><a href="https://arxiv.org/abs/2407.03913">arXiv</a></span><br>
                <span class="time">2024</span>
            </div>
        </div>
        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">AFlow: Automating Agentic Workflow Generation</strong><br>
                <span class="small-content">Jiayi Zhang<sup>&dagger;</sup>, Jinyu Xiang<sup>&dagger;</sup>, <strong>Zhaoyang Yu</strong>, Fengwei Teng, Xionghui Chen, Jiaqi Chen, Mingchen Zhuge, Xin Cheng, Sirui Hong, Jinlin Wang, Bingnan Zheng, Bang Liu, Yuyu Luo<sup>&ast;</sup>, Chenglin Wu<sup>&ast;</sup>.</span><br>
                <span class="small-content"><a href="https://arxiv.org/abs/2410.10762">arXiv</a></span><br>
                <span class="time">2024</span>
            </div>
        </div>
        
    </section>

    <section id="projects">
        <h2>Projects</h2>
        <!-- <div class="list-item">
            <div class="text-content">
                <strong class="big-name">Fibonacci Heap</strong><br>
                <span class="small-content">Fibonacci Heap Implemented by C++</span><br>
                <span class="small-content"><a href="https://github.com/woodfrog/FibonacciHeap">Link</a></span><br>
                <span class="time">2022</span>  
            </div>
            <table style="float: right; border: none;">
                <tr>
                    <td style="border: none;">
                        <a href="https://github.com/woodfrog/FibonacciHeap/forks">
                            <img src="https://img.shields.io/github/forks/woodfrog/FibonacciHeap" alt="fork">
                        </a>
                    </td>
                    <td style="border: none;">
                        <a href="https://github.com/woodfrog/FibonacciHeap/stargazers">
                            <img src="https://img.shields.io/github/stars/woodfrog/FibonacciHeap" alt="star">
                        </a>
                    </td>
                </tr>
            </table>
        </div> -->

        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">Math Agent</strong><br>
                <span class="small-content">Alibaba Global Mathematics Competition AI Challenge <span style="color: cadetblue"><strong>Top 3 (500+ teams)</strong></span></span><br>
                <!-- - <span class="small-content">Used multi-agent framework to solve complicated math questions automatically.</span><br>
                - <span class="small-content">Classified math questions through Gate Controller and human-designed strategy.</span><br>
                - <span class="small-content">Broke down the solution of questions into multiple phases (logic validate, logical reasoning, ...) and formed the final answer by Solution Refiner.</span><br> -->
                <span class="time">2024</span>  
            </div>
            <table style="float: right; border: none;">
                <tr>
                    <td style="border: none;">
                    </td>
                    <td style="border: none;">
                    </td>
                </tr>
            </table>
        </div>

        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">Audio-Visual Navigation & Emotional Perception of Xiaomi CyberDog</strong><br>
                - <span class="small-content">With the multi-modal perception ability of WenLan, the large-scale pre-training model, CyberDog can perform actions with different emotions in different scenes by capturing objects and the human-designed emotion-action mapping relationships.</span><br>
                - <span class="small-content">Based on SoundSpaces and reinforcement learning, we desigend a multi-modal navigation model framwork and deploy to CyberDog in the real environment.</span><br>
                <!-- - <span class="small-content">The network is based on RNN and use CNNs to extract multi-modal environmental information (visual and auditory).</span><br>
                - <span class="small-content">Used PPO to train the model on the SoundSpaces dataset and deploy to CyberDog in a real environment.</span><br> -->
                <span class="small-content">Advised by Prof. <a href="https://dtaoo.github.io/">Di Hu</a> and Prof. <a href="https://gsai.ruc.edu.cn/english/rsong">Ruihua Song</a></span><br>
                <span class="small-content"><a href="https://three-cyber-dogers.github.io/">GeWu-Lab</a> • <a href="https://www.bilibili.com/video/BV1FS4y1i7JR/">Bilibili[1]</a> • <a href="https://www.bilibili.com/video/BV1cT4y1W7mq/">Bilibili[2]</a></span><br>
                <span class="time">2022-2023</span>  
            </div>
            <table style="float: right; border: none;">
                <tr>
                    <td style="border: none;">
                    </td>
                    <td style="border: none;">
                    </td>
                </tr>
            </table>
        </div>

        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">Sensory Substitution for the Blind</strong><br>
                - <span class="small-content">SSD Technology Research: make the visually disabled 'SEE' the world again (with the help of Beijing Disabled Persons' Foundation).</span><br>
                <!-- - <span class="small-content">Used an external sensory substitution device to convert the image in front of the blind into sound via a human-designed mapping function.</span><br>
                - <span class="small-content">With the coopertaion of Beijing Disabled Persons' Foundation, conducted several testing experiments.</span><br>
                - <span class="small-content">Wrote and recorded a full set of audio electronic instructions for the blind.</span><br> -->
                <span class="small-content"><a href="https://zhuanlan.zhihu.com/p/303239531">Zhihu</a> • <a href="https://gewu-lab.github.io/project/5_sensory-substitution-for-the-blind/">GeWu-Lab</a></span><br>
                <span class="time">2022-2023</span>  
            </div>
            <table style="float: right; border: none;">
                <tr>
                    <td style="border: none;">
                    </td>
                    <td style="border: none;">
                    </td>
                </tr>
            </table>
        </div>

        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">2D Horizontal Fighting Game of Shadow Puppet</strong><br>
                <span class="small-content">Tencent Youth Game Designer Challenge <span style="color: cadetblue"><strong>Merit Award</strong></span></span><br>
                <!-- - <span class="small-content">A 2D horizontal combat game featuring shadow puppets and traditional Chinese mythology.</span><br>
                - <span class="small-content">Used the Corgi Engine to design the enemy AI and game UI, and used C# code to achieve the protagonist's movement, attack and skills control.</span><br> -->
                <span class="time">2022</span>  
            </div>
            <table style="float: right; border: none;">
                <tr>
                    <td style="border: none;">
                    </td>
                    <td style="border: none;">
                    </td>
                </tr>
            </table>
        </div>

        <!-- <div class="list-item">
            <div class="text-content">
                <strong class="big-name">Prompt-Engineering-Guide</strong><br>
                <span class="small-content">Guides, papers, lecture, notebooks and resources for prompt engineering</span><br>
                <span class="small-content"><a href="https://github.com/dair-ai/Prompt-Engineering-Guide">Link</a></span><br>
                <span class="time">2024</span>  
            </div>
            <table style="float: right; border: none;">
                <tr>
                    <td style="border: none;">
                        <a href="https://github.com/dair-ai/Prompt-Engineering-Guide/forks">
                            <img src="https://img.shields.io/github/forks/dair-ai/Prompt-Engineering-Guide" alt="fork">
                        </a>
                    </td>
                    <td style="border: none;">
                        <a href="https://github.com/dair-ai/Prompt-Engineering-Guide/stargazers">
                            <img src="https://img.shields.io/github/stars/dair-ai/Prompt-Engineering-Guide" alt="star">
                        </a>
                    </td>
                </tr>
            </table>
        </div> -->

    </section>

    
    <!-- <section id="publications">
        <h2>Selected Publications</h2>
        <div class="publication">Adapting Large Language Models by Integrating Collaborative Semantics for Recommendation.</div>
        <div class="publication">A Survey of Large Language Models.</div>
    </section> -->

    <section id="education">
        <h2>Education</h2>
        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">Renmin University of China</strong><br>
                - <span class="small-content">B.E., Artificial Intelligence</span><br>
                - <span class="small-content">GPA 3.4/4.0</span><br>
                <span class="time">2020-2024</span>
            </div>
            <img src="./assets/img/ruc.png" alt="RUC Logo" class="logo">
        </div>
        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">Ca' Foscari University of Venice</strong><br>
                - <span class="small-content">Exchange, Information Technology</span><br>
                <span class="time">2022-2023</span>
            </div>
            <img src="./assets/img/ca-foscari.png" alt="Ca' Foscari Logo" class="logo">
        </div>
    </section>

    <section id="experience">
        <h2>Experience</h2>
        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">GeWu-Lab</strong><br>
                <span class="small-content">Research Intern</span><br>
                <!-- - <span class="small-content">Explored multi-modal tasks from the perspective of cross correlation coeffecient.</span><br>
                - <span class="small-content">Designed and trained the multi-modal navigation model based on reinforcement learning.</span><br> -->
                - <span class="small-content">Audio-Visual Navigation & Emotional Perception of Xiaomi CyberDog. Displayed as an excellent project on 2022 BAAI Conference.</span><br>
                <span class="time">2021.07-2022.08</span>
            </div>
            <img src="./assets/img/gewu.png" alt="GeWu Logo" class="logo">
        </div>
        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">Xiaomi - MiRoboticsLab</strong><br>
                <span class="small-content">Algorithm Engineer</span><br>
                - <span class="small-content">Developed a versatile AI agent for CyberDog by creating reusable APIs with Python and ROS2, implementing an LLM-based agent with custom classes, constructing a reasoning framework, enhancing multi-modal input processing, and enabling user-defined preset instructions for improved performance.</span><br>
                <!-- - <span class="small-content">Implemented LLM-based Embodied AI Agent with Langchain first, and then broke away from LangChian and used custom Python classes.</span><br>
                - <span class="small-content">Finished the reasoning Agent based on ReAct framework and the Python-style Code Generation Agent, completed the construction of the ability set and tried to take different ways to search in the massive text in ability set (BM25, vector database, ...).</span><br>
                - <span class="small-content">Changed the original text-only input to multi-modal input (vision + nlp instruction) and fine-tuned LLM and VLM (LoRA, QLoRA, FFT) for better instruction following.</span><br>
                - <span class="small-content">Added the function of preset instructions, users can add common instructions to speed up the reasoning and execution of the Agent.</span><br> -->
                <span class="time">2024.01-2024.04</span>
            </div>
            <img src="./assets/img/xiaomi.png" alt="Xiaomi Logo" class="logo">
        </div>        
        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">AI Engine Lab</strong><br>
                <span class="small-content">Research Intern</span><br>
                - <span class="small-content">Undergraduate Thesis: Multi-head Reflexion. Attempted to explore the memory module of autonomous agents.</span><br>
                <!-- - <span class="small-content">Discussed three problems of self-reflection that I discovered during experiment: randomness, stubbornness and misunderstanding.</span><br>
                - <span class="small-content">Inspired by Pinecone's tutorial: The agent is overconfident in its math ability, which causes it to not use the calculator tool to complete instructions. Sovled the problem by explicitly criticizing its math ability in the prompt words. With a similar idea, designed three reflectors for self-reflection, criticism and check respectively.</span><br>
                - <span class="small-content">Selected HotPotQA as the experimental dataset. By comparing the accuracy and variance of the five-time experiment with self-reflection, proved the effectiveness of the method.</span><br>
                - <span class="small-content">Future work may from a prompt perspective to help LLMs better capture critical information from redundant context.</span><br> -->
                <span class="time">2024.02-2024.06</span>
            </div>
            <img src="./assets/img/aiengine.jpeg" alt="AI Engine Logo" class="logo">
        </div>        
    </section>

    <section id="service">
        <h2>Service</h2>
        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">Microsoft Student Learning Ambassador</strong><br>
                - <span class="small-content">Promoting MS techniques and products, Organizing and participating in MS events</span><br>
                <span class="time">2021-2023</span>
            </div>
            <img src="./assets/img/ms.png" alt="MS Logo" class="logo">
        </div>
    </section>

    <section id="Award">
        <h2>Award</h2>
        <div class="list-item">
            <div class="text-content">
                - <span class="small-content">Sa Shixuan Scholarship (Second Prize) in RUC, School of Information</span>
                <span class="time">2024</span><br>
                - <span class="small-content">Alibaba Global Mathematics Competition AI Challenge Top 3 (500+ teams)</span>
                <span class="time">2024</span><br>
                - <span class="small-content">The 15th National College Student Mathematics Competition Second Prize</span>
                <span class="time">2023</span><br>
                - <span class="small-content">Tencent Youth Game Designer Challenge Merit Award</span>
                <span class="time">2022</span><br>
                - <span class="small-content">MCM/ICM Contest Meritorious Winner (top 7%)</span>
                <span class="time">2022</span><br>
                - <span class="small-content">2020-2021 Learning Excellence Scholarship in RUC</span>
                <span class="time">2020-2021</span>
            </div>
        </div>
    </section>

    <section id="Misc">
        <h2>Misc</h2>
        <div class="list-item">
            <div class="text-content">
                - <span class="small-content">Xiaomi CyberDog Emotional Development (Chinese) <a href="https://zhuanlan.zhihu.com/p/525114839">[Link]</a></span>
                <span class="time">2022</span><br>
            </div>
        </div>
    </section>

    <img alt="GitHub last commit" src="https://img.shields.io/github/last-commit/MoshiQAQ/moshiqaq.github.io?label=Latest%20Update">

    <br>

    <script>
        // Example JavaScript for potential interactivity
        document.addEventListener('DOMContentLoaded', function() {
            // Add any JS-based interactivity here
        });
    </script>

</body>
</html>
