<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Zhaoyang Yu's Homepage</title>
    <style>
        body { 
            font-family: Arial, sans-serif; 
            margin: 0; 
            padding: 0; 
            padding-top: 50px;
            display: flex; 
            flex-direction: column; 
            align-items: center; 
            justify-content: center; 
            min-height: 100vh; 
            text-align: center; 
            margin-left: 27%;
            margin-right: 27%;
        }
        header { 
            display: flex; 
            align-items: center; 
            justify-content: flex-start; 
            width: 80%; 
            margin-bottom: 20px; 
        }
        header img {
            margin-left: 16%;
            margin-right: 16%; /* Adds space between the image and the text */
        }
        header > div {
            text-align: left; /* Aligns the text to the left */
        }
        section { 
            margin-bottom: 20px; 
            width: 80%; 
        }
        h2 { 
            text-align: left; 
            width: 100%;
        }
        h2::after {
            content: "";
            display: block;
            height: 2px;
            width: 100%;
            background: linear-gradient(to right, gray, transparent, transparent);
            margin-top: 5px;
        }
        .publication, .experience { 
            margin-left: 20px; 
            text-align: left; 
        }
        .publication:before, .experience:before { 
            content: "- "; 
        }
        .logo {
            height: 50px; /* Adjust based on your preference */
            margin-left: 10px; /* Adds space between the text and the logo */
            vertical-align: middle; /* Aligns the logo with the middle of the text */
        }
        .list-item{
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 10px;
        }
        .text-content {
            text-align: left;
            font-size: 1.1em;
        }
        .time {
            font-style: italic;
            font-size: 0.6em;
            color: gray;
        }
        .big-name{
            font-size: 1em;
            margin-bottom: 10px;
        }
        .small-content{
            font-size: 0.9em;
        }
        a:link, a:visited, a:hover, a:active {
            color: blue; /* Keeps the link color consistent with the surrounding text or specified color */
            text-decoration: none; /* Removes underline from links */
        }
        @media (max-width: 600px) {
            /* 手机端不显示头像 */
            header img {
                display: none;
            }
            body, header, section {
                margin-left: 10px; /* 在手机屏幕上减少左边距 */
                margin-right: 10px; /* 在手机屏幕上减少右边距 */
            }
            header{
                /* 左对齐 */
                text-align: left;
                width: auto; /* 让header的宽度自适应 */
            }
            section {
                width: calc(100% - 20px); /* 让section的宽度自适应 */
            }
        }
    </style>
</head>
<body>
    <header>
        <img src="./assets/img/zhaoyang_512.png" alt="Zhaoyang Yu" style="height: 150px;"> <!-- Adjust the image path and style as needed -->
        <div>
            <h1>Zhaoyang Yu<br>于兆洋</h1>
            <p>Email: yuzhaoyang0713 [AT] ruc.edu.cn</p> <!-- Update the email address -->
            <p><a href="https://github.com/MoshiQAQ">GitHub</a> • <a href="https://www.zhihu.com/people/arecritezhu">Zhihu</a> • <a href="https://twitter.com/ZhaoyangYu22356">Twitter</a></p>
        </div>
    </header>

    <section id="bio">
        <p class="text-content">I received my undergraduate degree from Gaoling School of AI, Renmin University of China in June 2024. I'm actively seeking a <strong>PhD</strong> position at present. My research interest include <strong>LLM Agents</strong> and <strong>LLM Reasoning</strong>.</p>
        <!-- <p class="text-content">From 2021 to 2022, I had the privilege of studying computer vision, multi-modal machine learning, and robotics under the mentorship of Prof.
        <a href="https://dtaoo.github.io/">Di Hu</a>. In 2024, I engaged in research on the memory mechanisms of LLMs Agent, advised by Prof. <a href="https://xu-chen.com/">Xu Chen</a>.</p> -->
    </section>

    <section id="publications">
        <h2>Publications</h2>
        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">MobileExperts: A Dynamic Tool-Enabled Agent Team in Mobile Devices</strong><br>
                <span class="small-content">Jiayi Zhang, Chuang Zhao, Yihan Zhao, <strong>Zhaoyang Yu</strong>, Ming He, Jianping Fan<sup>&ast;</sup>.</span><br>
                <span class="small-content"><a href="https://arxiv.org/abs/2407.03913">arXiv</a></span><br>
                <span class="time">2024</span>
            </div>
        </div>
        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">AFlow: Automating Agentic Workflow Generation</strong><br>
                <span class="small-content">Jiayi Zhang<sup>&dagger;</sup>, Jinyu Xiang<sup>&dagger;</sup>, <strong>Zhaoyang Yu</strong>, Fengwei Teng, Xionghui Chen, Jiaqi Chen, Mingchen Zhuge, Xin Cheng, Sirui Hong, Jinlin Wang, Bingnan Zheng, Bang Liu, Yuyu Luo<sup>&ast;</sup>, Chenglin Wu<sup>&ast;</sup>.</span><br>
                <span class="small-content"><a href="https://arxiv.org/abs/2410.10762">arXiv</a> • <a href="https://github.com/geekan/MetaGPT/tree/main/examples/aflow">Github</a></span><br>
                <span class="time">ICLR 2025 <strong>Oral</strong></span>
            </div>
        </div>
        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">Self-Supervised Prompt Optimization</strong><br>
                <span class="small-content">Jinyu Xiang<sup>&dagger;</sup>, Jiayi Zhang<sup>&dagger;</sup>, <strong>Zhaoyang Yu</strong>, Fengwei Teng, Jinhao Tu, Xinbing Liang, Sirui Hong, Chenglin Wu<sup>&ast;</sup>, Yuyu Luo<sup>&ast;</sup>.</span><br>
                <span class="small-content"><a href="https://arxiv.org/abs/2502.06855">arXiv</a></span><br>
                <span class="time">2025</span>
            </div>
        </div>
        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">Atom of Thoughts for Markov LLM Test-Time Scaling</strong><br>
                <span class="small-content">Fengwei Teng, <strong>Zhaoyang Yu</strong>, Quan Shi, Jiayi Zhang, Chenglin Wu<sup>&ast;</sup>, Yuyu Luo</span><br>
                <span class="small-content"><a href="https://arxiv.org/abs/2502.12018">arXiv</a></span><br>
                <span class="time">2025</span>
            </div>
        </div>
        <!-- <div class="list-item">
            <div class="text-content">
                <strong class="big-name">Eval-Free Agentic Workflow Generation</strong><br>
                <span class="small-content">Authorship order to be confirmed</span><br>
                <span class="small-content">Under review</span><br>
                <span class="time">2025</span>
            </div>
        </div> -->
    </section>

    <section id="projects">
        <h2>Projects</h2>
        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">Multi-Agent Workflow for Alibaba Global Math Competition</strong><br>
                - <span class="small-content">Designed a multi-agent workflow to automate the solving of complex mathematical problems.</span><br>
                - <span class="small-content">Developed a Gate Controller for categorizing math questions, employing a combination of AI and human-designed strategies for efficient question routing.</span><br>
                - <span class="small-content">Devised a multi-phase solution process for question answering, including logic validation and reasoning, culminating in a refined final answer through the Solution Refiner.</span><br>
                <span class="time">2024</span>  
            </div>
            <table style="float: right; border: none;">
                <tr>
                    <td style="border: none;">
                    </td>
                    <td style="border: none;">
                    </td>
                </tr>
            </table>
        </div>        
        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">Audio-Visual Navigation on CyberDog</strong><br>
                - <span class="small-content">Integrated the capabilities of large-scale pre-trained multimodal models into robots, enabling them to perform diverse actions in different visual situations.</span><br>
                - <span class="small-content">Leveraged PPO (Proximal Policy Optimization) and self-designed multimodal navigation model to achieve robot navigation in real-world environments.</span><br>
                <span class="small-content">Advised by Prof. <a href="https://dtaoo.github.io/">Di Hu</a> and Prof. <a href="https://gsai.ruc.edu.cn/english/rsong">Ruihua Song</a></span><br>
                <span class="small-content"><a href="https://three-cyber-dogers.github.io/">GeWu-Lab</a> • <a href="https://www.bilibili.com/video/BV1FS4y1i7JR/">Bilibili[1]</a> • <a href="https://www.bilibili.com/video/BV1cT4y1W7mq/">Bilibili[2]</a></span><br>
                <span class="time">2022-2023</span>  
            </div>
            <table style="float: right; border: none;">
                <tr>
                    <td style="border: none;">
                    </td>
                    <td style="border: none;">
                    </td>
                </tr>
            </table>
        </div>

        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">Sensory Substitution for the Blind (Public Welfare Projects)</strong><br>
                - <span class="small-content">To make the visually disabled 'SEE' the world again (with the help of Beijing Disabled Persons' Foundation).</span><br>
                <span class="small-content"><a href="https://zhuanlan.zhihu.com/p/303239531">Zhihu</a> • <a href="https://gewu-lab.github.io/project/5_sensory-substitution-for-the-blind/">GeWu-Lab</a></span><br>
                <span class="time">2022-suspended</span>  
            </div>
            <table style="float: right; border: none;">
                <tr>
                    <td style="border: none;">
                    </td>
                    <td style="border: none;">
                    </td>
                </tr>
            </table>
        </div>

        <!-- <div class="list-item">
            <div class="text-content">
                <strong class="big-name">Prompt-Engineering-Guide</strong><br>
                <span class="small-content">Guides, papers, lecture, notebooks and resources for prompt engineering</span><br>
                <span class="small-content"><a href="https://github.com/dair-ai/Prompt-Engineering-Guide">Link</a></span><br>
                <span class="time">2024</span>  
            </div>
            <table style="float: right; border: none;">
                <tr>
                    <td style="border: none;">
                        <a href="https://github.com/dair-ai/Prompt-Engineering-Guide/forks">
                            <img src="https://img.shields.io/github/forks/dair-ai/Prompt-Engineering-Guide" alt="fork">
                        </a>
                    </td>
                    <td style="border: none;">
                        <a href="https://github.com/dair-ai/Prompt-Engineering-Guide/stargazers">
                            <img src="https://img.shields.io/github/stars/dair-ai/Prompt-Engineering-Guide" alt="star">
                        </a>
                    </td>
                </tr>
            </table>
        </div> -->

    </section>

    
    <!-- <section id="publications">
        <h2>Selected Publications</h2>
        <div class="publication">Adapting Large Language Models by Integrating Collaborative Semantics for Recommendation.</div>
        <div class="publication">A Survey of Large Language Models.</div>
    </section> -->

    <section id="education">
        <h2>Education</h2>
        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">Renmin University of China</strong><br>
                - <span class="small-content">B.E., Artificial Intelligence</span><br>
                <!-- - <span class="small-content">GPA 3.4/4.0</span><br> -->
                <span class="time">2020-2024</span>
            </div>
            <img src="./assets/img/ruc.png" alt="RUC Logo" class="logo">
        </div>
    </section>

    <section id="experience">
        <h2>Experience</h2>
        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">GeWu-Lab</strong><br>
                <span class="small-content">Research Intern</span><br>
                <!-- - <span class="small-content">Explored multi-modal tasks from the perspective of cross correlation coeffecient.</span><br>
                - <span class="small-content">Designed and trained the multi-modal navigation model based on reinforcement learning.</span><br> -->
                - <span class="small-content">Audio-Visual Navigation on CyberDog. Displayed as an excellent project on 2022 BAAI Conference.</span><br>
                <span class="time">2021.07-2022.08</span>
            </div>
            <img src="./assets/img/gewu.png" alt="GeWu Logo" class="logo">
        </div>
        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">Xiaomi - MiRoboticsLab</strong><br>
                <span class="small-content">Algorithm Engineer</span><br>
                - <span class="small-content">Constructed a dataset structured as (instruction, action sequence) pairs based on human preferences, which is utilized for the fine-tuning of MiLM.</span><br>
                - <span class="small-content">Deployed the fine-tuned MiLM and utilized an iterative reasoning process to enable the execution of simple voice commands on CyberDog.</span><br>
                <!-- - <span class="small-content">Implemented LLM-based Embodied AI Agent with Langchain first, and then broke away from LangChian and used custom Python classes.</span><br>
                - <span class="small-content">Finished the reasoning Agent based on ReAct framework and the Python-style Code Generation Agent, completed the construction of the ability set and tried to take different ways to search in the massive text in ability set (BM25, vector database, ...).</span><br>
                - <span class="small-content">Changed the original text-only input to multi-modal input (vision + nlp instruction) and fine-tuned LLM and VLM (LoRA, QLoRA, FFT) for better instruction following.</span><br>
                - <span class="small-content">Added the function of preset instructions, users can add common instructions to speed up the reasoning and execution of the Agent.</span><br> -->
                <span class="time">2024.01-2024.04</span>
            </div>
            <img src="./assets/img/xiaomi.png" alt="Xiaomi Logo" class="logo">
        </div>        
        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">AI Engine Lab</strong><br>
                <span class="small-content">Research Intern</span><br>
                - <span class="small-content">Undergraduate Thesis: Multi-head Reflexion. Discussed three weaknesses of reflexion: randomness, stubbornness and misunderstanding. Desigend specialized reflexion head with personas to overcome these shortcomings.</span><br>
                <!-- - <span class="small-content">Discussed three problems of self-reflection that I discovered during experiment: randomness, stubbornness and misunderstanding.</span><br>
                - <span class="small-content">Inspired by Pinecone's tutorial: The agent is overconfident in its math ability, which causes it to not use the calculator tool to complete instructions. Sovled the problem by explicitly criticizing its math ability in the prompt words. With a similar idea, designed three reflectors for self-reflection, criticism and check respectively.</span><br>
                - <span class="small-content">Selected HotPotQA as the experimental dataset. By comparing the accuracy and variance of the five-time experiment with self-reflection, proved the effectiveness of the method.</span><br>
                - <span class="small-content">Future work may from a prompt perspective to help LLMs better capture critical information from redundant context.</span><br> -->
                <span class="time">2024.02-2024.06</span>
            </div>
            <img src="./assets/img/aiengine.jpeg" alt="AI Engine Logo" class="logo">
        </div>        
    </section>

    <section id="service">
        <h2>Service</h2>
        <div class="list-item">
            <div class="text-content">
                <strong class="big-name">Microsoft Student Learning Ambassador</strong><br>
                - <span class="small-content">Promoting MS techniques and products, Organizing and participating in MS events</span><br>
                <span class="time">2021-2023</span>
            </div>
            <img src="./assets/img/ms.png" alt="MS Logo" class="logo">
        </div>
    </section>

    <section id="Award">
        <h2>Award</h2>
        <div class="list-item">
            <div class="text-content">
                - <span class="small-content">Sa Shixuan Scholarship (Second Prize) in RUC, School of Information</span>
                <span class="time">2024</span><br>
                - <span class="small-content">Alibaba Global Mathematics Competition AI Challenge <span style="color: cadetblue"><strong>Top 3 (500+ teams)</strong></span></span>
                <span class="time">2024</span><br>
                - <span class="small-content">The 15th National College Student Mathematics Competition Second Prize</span>
                <span class="time">2023</span><br>
                - <span class="small-content">Tencent Youth Game Designer Challenge <span style="color: cadetblue"><strong>Merit Award</strong></span></span>
                <span class="time">2022</span><br>
                - <span class="small-content">MCM/ICM Contest Meritorious Winner (top 7%)</span>
                <span class="time">2022</span><br>
                - <span class="small-content">2020-2021 Learning Excellence Scholarship in RUC</span>
                <span class="time">2020-2021</span>
            </div>
        </div>
    </section>

    <section id="Misc">
        <h2>Misc</h2>
        <div class="list-item">
            <div class="text-content">
                - <span class="small-content">Xiaomi CyberDog Emotional Development (Chinese) <a href="https://zhuanlan.zhihu.com/p/525114839">[Link]</a></span>
                <span class="time">2022</span><br>
            </div>
        </div>
    </section>

    <img alt="GitHub last commit" src="https://img.shields.io/github/last-commit/MoshiQAQ/moshiqaq.github.io?label=Latest%20Update">

    <br>

    <script>
        // Example JavaScript for potential interactivity
        document.addEventListener('DOMContentLoaded', function() {
            // Add any JS-based interactivity here
        });
    </script>

</body>
</html>
